import math
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.cluster import KMeans
from scipy.stats import linregress, kurtosis
from sklearn.model_selection import GridSearchCV

def plot_histograms(df, nrows=8, ncols=2, figsize=(20, 20), bins=30):
    """
    Generates histograms for continuous variables in a DataFrame.

    Args:
        df (pd.DataFrame): DataFrame containing continuous variables.
        nrows (int): Number of rows in the subplot grid.
        ncols (int): Number of columns in the subplot grid.
        figsize (tuple): Figure size.
        bins (int): Number of bins for histograms.

    Returns:
        None
    """
    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)
    axes = axes.flatten()  # Flatten the 2D axes array for easy indexing

    for i, column in enumerate(df.columns):
        axes[i].hist(df[column], bins=bins, edgecolor='black')
        axes[i].set_title(column, fontsize=10)
        axes[i].set_xlabel('')
        axes[i].set_ylabel('')

    # Remove unused subplots if fewer columns than available axes
    for j in range(len(df.columns), len(axes)):
        fig.delaxes(axes[j])

    plt.tight_layout()
    plt.show()



def plot_correlations(data_df: pd.DataFrame, correlations_df: pd.DataFrame) -> None:
    '''Takes a Pandas dataframe of features and a correlation dataframe for some or
    all of those features generated by get_correlations(). Plots each feature pair
    as scatter with best fit line. Uses kurtosis cutoff to decide which axes to log.'''

    fig, axs=plt.subplots(3,5, figsize=(11,7))
    fig.suptitle('Feature cross-correlations')

    for ax, (_, row) in zip(axs.flat, correlations_df.iterrows()):

        # Linear regression to show on plot
        feature_pair_data=data_df[[row['Feature 1'], row['Feature 2']]].dropna()
        regression=linregress(feature_pair_data.iloc[:,0], feature_pair_data.iloc[:,1])
        regression_x=np.linspace(min(feature_pair_data.iloc[:,0]),max(feature_pair_data.iloc[:,0]))
        regression_y=regression.slope*regression_x + regression.intercept

        # Draw scatter plot with regression line
        ax.scatter(data_df[row['Feature 1']], data_df[row['Feature 2']], s=0.2, color='black')
        ax.plot(regression_x, regression_y, color='red')
        ax.set_xlabel(row['Feature 1'])
        ax.set_ylabel(row['Feature 2'])

        if kurtosis(data_df[row['Feature 1']].dropna()) > 40:
            ax.set_xscale('log')

        if kurtosis(data_df[row['Feature 2']].dropna()) > 40:
            ax.set_yscale('log')

    fig.tight_layout()


def plot_boxplots(df, exclude_feature="Calories", n_cols=2, figsize_multiplier=(8, 5)):
    """
    Generates boxplots comparing Calories Burned to other numeric features.

    Args:
        df (pd.DataFrame): DataFrame containing numeric features.
        exclude_feature (str): Feature to exclude from the comparison (default: 'Calories').
        n_cols (int): Number of columns for subplot grid (default: 2).
        figsize_multiplier (tuple): Multiplier for figure size dimensions (default: (8, 5)).

    Returns:
        None
    """
    # Only use numeric columns and exclude the specified feature
    features = df.select_dtypes(include=['float64', 'int64']).columns.tolist()
    features = [f for f in features if f != exclude_feature]

    # Determine layout
    n_features = len(features)
    n_rows = math.ceil(n_features / n_cols)
    
    fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * figsize_multiplier[0], n_rows * figsize_multiplier[1]))
    axs = axs.flatten()
    
    fig.suptitle(f'Comparison of {exclude_feature} Burned and Numeric Features', fontsize=28)
    
    for idx, feature in enumerate(features):
        plot_df = df[[feature, exclude_feature]].dropna().copy()
        
        # Bin Calories into defined ranges
        plot_df[f'{exclude_feature}_bin'] = pd.cut(
            plot_df[exclude_feature], 
            bins=[0,100,200,300,400,500,600,800,1000],
            labels=['0-100','100-200','200-300','300-400','400-500','500-600','600-800','800-1000']
        )
        plot_df = plot_df.dropna(subset=[f'{exclude_feature}_bin'])

        # Create boxplot
        sns.boxplot(data=plot_df, x=f'{exclude_feature}_bin', y=feature, ax=axs[idx])
        
        # Set only ticks for bins with data
        bins_in_data = plot_df[f'{exclude_feature}_bin'].dropna().unique()
        axs[idx].set_xticks(range(len(bins_in_data)))
        axs[idx].set_xticklabels(bins_in_data, rotation=45, ha='right')
        
        axs[idx].set_title(feature, fontsize=18)
        axs[idx].set_xlabel(f'{exclude_feature} Burned (Binned)', fontsize=14)
    
    # Remove unused axes
    for j in range(idx + 1, len(axs)):
        fig.delaxes(axs[j])
    
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()

def plot_correlation_heatmap(df, figsize=(10, 8), cmap="coolwarm"):
    """
    Generates a correlation heatmap for numeric features.

    Args:
        df (pd.DataFrame): DataFrame containing numeric features.
        figsize (tuple): Size of the heatmap figure (default: (10, 8)).
        cmap (str): Colormap for the heatmap (default: 'coolwarm').

    Returns:
        None
    """
    # Compute correlation matrix for numeric columns
    corr_matrix = df.select_dtypes(include=['float64', 'int64']).corr()

    # Plot heatmap
    plt.figure(figsize=figsize)
    sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap=cmap, square=True, cbar_kws={"shrink": 0.8})

    plt.title("Correlation Heatmap (with Encoded 'Workout Type')", fontsize=18)
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)
    plt.tight_layout()
    plt.show()

'''Distribution Analysis'''
def plot_distribution(df, numerical_features, bins=30, add_kde=True):
    """Plots separate histograms with optional KDE for better readability."""

    num_features = len(numerical_features)
    fig, axes = plt.subplots(nrows=num_features, ncols=1, figsize=(8, num_features * 4))

    for i, feature in enumerate(numerical_features):
        sns.histplot(df[feature], bins=bins, kde=add_kde, ax=axes[i])
        axes[i].set_title(f"Distribution of {feature}")

    plt.tight_layout()
    plt.show()

'''Correlation Analysis'''
def correlation_analysis(df):

    """Displays correlation heatmap of dataset."""
    correlation_matrix = df.corr()
    plt.figure(figsize=(10,6))
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
    plt.title('Feature Correlation Matrix')
    plt.show()

'''K-Means Clustering'''
def cluster_users(df, num_clusters=3):

    """Clusters users based on workout efficiency metrics."""
    X = df[['Age', 'Weight', 'Duration', 'Calories', 'Heart_Rate', 'Body_Temp']]
    kmeans = KMeans(n_clusters=num_clusters, random_state=42)
    df['Cluster'] = kmeans.fit_predict(X)

    """Plot Clusters"""
    plt.figure(figsize=(8,6))
    sns.scatterplot(x=df['Calories'], y=df['Duration'], hue=df['Cluster'], palette='Set1')
    plt.title('User Clustering by Workout Efficiency')
    plt.show()

    return df

def plot_kde(df, numerical_features):
    """Plots KDE (density curves) for numerical features."""
    plt.figure(figsize=(12, 6))

    for feature in numerical_features:
        sns.kdeplot(df[feature], label=feature, fill=True)

    plt.title("Feature Density Comparisons")
    plt.legend()
    plt.show()


def plot_relationship(df, feature_x, feature_y):
    """Plots scatter plot to visualize relationships."""
    plt.figure(figsize=(8,6))
    sns.scatterplot(x=df[feature_x], y=df[feature_y])
    plt.title(f'{feature_x} vs {feature_y}')
    plt.show()

def plot_cross_validation(search_results:GridSearchCV) -> None:
    '''Takes result object from scikit-learn's GridSearchCV(),
    draws plot of hyperparameter set validation score rank vs
    training and validation scores.'''

    results=pd.DataFrame(search_results.cv_results_)
    sorted_results=results.sort_values('rank_test_score')

    plt.title('Hyperparameter optimization')
    plt.xlabel('Hyperparameter set validation accuracy rank')
    plt.ylabel('Validation accuracy (%)')
    plt.gca().invert_xaxis()

    plt.fill_between(
        sorted_results['rank_test_score'],
        sorted_results['mean_test_score']*100 + sorted_results['std_test_score']*100,
        sorted_results['mean_test_score']*100 - sorted_results['std_test_score']*100,
        alpha=0.5
    )

    plt.plot(
        sorted_results['rank_test_score'],
        sorted_results['mean_test_score']*100,
        label='Validation'
    )

    plt.fill_between(
        sorted_results['rank_test_score'],
        sorted_results['mean_train_score']*100 + sorted_results['std_train_score']*100,
        sorted_results['mean_train_score']*100 - sorted_results['std_train_score']*100,
        alpha=0.5
    )

    plt.plot(
        sorted_results['rank_test_score'],
        sorted_results['mean_train_score']*100,
        label='Training'
    )

    plt.legend(loc='best', fontsize='small')
    plt.show()


def plot_residuals(model, X_test, y_test, model_name):
    """Plots residuals to visualize errors."""
    y_pred = model.predict(X_test)
    residuals = y_test - y_pred

    plt.figure(figsize=(6, 4))
    plt.scatter(y_pred, residuals, alpha=0.6)
    plt.axhline(y=0, color='r', linestyle='--')
    plt.xlabel("Predicted Values")
    plt.ylabel("Residuals")
    plt.title(f"{model_name} Residual Plot")
    plt.show()


def evaluate_model(model, X_test, y_test, model_name):
    """
    Evaluates a model using R-squared and residual plots.

    Args:
        model: Trained machine learning model.
        X_test (pd.DataFrame or np.array): Test feature dataset.
        y_test (pd.Series or np.array): True labels for test data.
        model_name (str): Name of the model for display.

    Returns:
        float: R-squared score of the model.
    """
    # Compute R-squared
    r_sq = model.score(X_test, y_test)
    print(f"{model_name} R-squared: {r_sq:.4f}")

    # Residual plot
    y_pred = model.predict(X_test)
    residuals = y_test - y_pred

    plt.figure(figsize=(6, 4))
    plt.scatter(y_pred, residuals, alpha=0.6)
    plt.axhline(y=0, color='r', linestyle='--')
    plt.xlabel("Predicted Values")
    plt.ylabel("Residuals")
    plt.title(f"{model_name} Residual Plot")
    plt.show()

    return r_sq

def compare_all_distributions(df_original, df_imputed):
    cols = df_original.columns
    for col in cols:
        plt.figure(figsize=(8, 4))
        sns.kdeplot(df_original[col].dropna(), label='Original', fill=True)
        sns.kdeplot(df_imputed[col].dropna(), label='Imputed', fill=True)
        plt.title(f'Distribution Comparison: {col}')
        plt.xlabel(col)
        plt.ylabel('Density')
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        plt.show()